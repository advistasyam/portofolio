---
title: 'Implementing Docker'
date: '2022-05-11'
lastmod: '2022-05-11'
tags: ['software engineering', 'dev ops']
draft: false
summary: 'Explore the benefits of using Docker, such as improved scalability, resource efficiency, and easier deployment and management of applications.'
images: ['/static/images/blog/docker_img1.webp']
authors: ['default']
---

<div className={'flex items-center justify-center'}>
  ![thumbnail](/static/images/blog/docker_img1.webp)
</div>

<br />

# Docker

Docker is an open-source application that serves as a container for packaging and deploying software along with all its dependencies, enabling the software to function seamlessly. The configuration of the software and its supporting files/dependencies are bundled into an Image (a term used in Docker). Subsequently, an instance of this Image is referred to as a Container.

Docker was launched in 2013 and allows software to be isolated from its environment, thereby solving the problem of software being limited to running in specific environments only.

# Container

Containers work by encapsulating application code along with all its dependencies, allowing it to run in various environments. Unlike Virtual Machines (VMs) that have their own OS for each VM, Containers are an abstraction of the app layer, requiring only one OS, enabling them to run more applications and being lighter in terms of memory and processing time compared to VMs.

# Usage

In software development using GitLab, GitLab facilitates the use of Docker Engine through GitLab Runner. With GitLab CI/CD, Docker will run the application in a container based on the image defined at the beginning.

For example, if we are working with Django via GitLab, implementing Docker can start with creating a Dockerfile, like this:

```dockerfile
FROM python:3.8-slim

RUN apt-get update
RUN apt-get install -y libpq-dev gcc

RUN mkdir -p /app
COPY ./requirements.txt .
# Web server will listen to this port
EXPOSE 8000
# Install requirements
RUN pip install -U -r requirements.txt

COPY ./paytungan /app
WORKDIR /app

RUN python manage.py collectstatic --noinput

RUN chmod +x run.sh
```

FROM specifies the image to be used in Docker, which can be considered as dependencies. The RUN command executes a specified command, such as RUN mkdir, which creates a new directory in the container. Finally, EXPOSE informs Docker that the container will open port 8000 as the application port.

Next step is to create a **docker-compose.yml** file.

docker-compose.yml is a YAML file that can be used to define which containers need to be created. With one docker-compose.yml file, we can define 3 containers with different functions. For example, one for the web server, one for the backend, and one for the database.

For instance, it can look like this:

```yaml
version: '2'
services:
  db:
    image: postgres
  django:
    build: .
    restart: always
    container_name: paytunganapp
    command: python manage.py runserver 0.0.0.0:8000
    ports:
      - '8000:8000'
    depends_on:
      - db
```

The 'db' service specifies the image used for the database, while the 'django' service runs the chosen framework. The commands after this line execute the Django web server that has been set up.

Finally, you need to create a 'gitlab-ci.yml' file that stores the configuration for GitLab Runner. It might look something like this:

```yaml
stages:
  - test
  - build
  - deploy
test:
  stage: test
  script: echo "Testing the app"
build:
  stage: build
  script:
    - echo "Building the app"
    - docker-compose build
deploy_staging:
  stage: deploy
  only:
    - master
  script:
    - echo "Deploying the app"
    - docker-compose up -d
```

In this example, 3 stages are implemented (test, build, and deploy_staging). The first stage is for testing, the second one is for building the image, and the third one is for running the container based on the created image.
